{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data from Original Source (Fulton Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "FULTON_DIR = './data/raw_fulton/'\n",
    "fulton_files = os.listdir(FULTON_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_keyword(filename: str, keywords: list[str]) -> str:\n",
    "    return any(keyword in filename for keyword in keywords)\n",
    "\n",
    "def clean_and_cast_column(column: pd.Series, var_map: dict) -> pd.Series:\n",
    "    to_dtype = var_map[column.name] \n",
    "    fill_val = None\n",
    "    \n",
    "    if to_dtype == \"int\" or to_dtype == \"float\":\n",
    "        fill_val = 0\n",
    "    elif to_dtype == \"string\":\n",
    "        fill_val = \"\"\n",
    "    else:\n",
    "        raise ValueError(f\"{to_dtype} is not a valid data type!\")\n",
    "    \n",
    "    if ((to_dtype == \"int\" or to_dtype == \"float\")\n",
    "        and (column.dtype == \"string\" or column.dtype == \"object\")):\n",
    "        # Remove commas from number strings before converting\n",
    "        column = column.astype(\"str\").str.replace(\",\", \"\").astype('float')\n",
    "    \n",
    "    # Record number of filled nulls\n",
    "    print(f\"Number of nulls in column {column.name}: {column.isna().sum()}\")\n",
    "    \n",
    "    column = column.fillna(fill_val)\n",
    "    return column.astype(to_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a single file with all LUC == 101 Fulton County Digest (Parcel) Data for all Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"DIGEST\", \"NF\", \"SF\"]\n",
    "digest_cols = {\n",
    "    \"Taxyr\": \"int\",\n",
    "    \"Parid\": \"string\",\n",
    "    \"Situs Adrno\": \"int\",\n",
    "    \"Situs Adrdir\": \"string\",\n",
    "    \"Situs Adrstr\": \"string\",\n",
    "    \"Situs Adrsuf\": \"string\",\n",
    "    \"Cityname\": \"string\",\n",
    "    \"Luc\": \"string\",\n",
    "    \"Calcacres\": \"float\",\n",
    "    \"Own1\": \"string\",\n",
    "    \"Own2\": \"string\",\n",
    "    \"Owner Adrno\": \"int\",\n",
    "    \"Owner Adradd\": \"string\",\n",
    "    \"Owner Adrdir\": \"string\",\n",
    "    \"Owner Adrstr\": \"string\",\n",
    "    \"Owner Adrsuf\": \"string\",\n",
    "    \"Cityname.1\": \"string\",\n",
    "    \"Statecode\": \"string\",\n",
    "    \"Zip1\": \"string\",\n",
    "    \"Aprtot\": \"float\",\n",
    "    \"D Yrblt\": \"int\",\n",
    "    \"D Effyr\": \"int\",\n",
    "    \"D Yrremod\": \"int\",\n",
    "    \"Sfla\": \"float\",\n",
    "    \"Rmbed\": \"int\",\n",
    "    \"Fixbath\": \"int\",\n",
    "    \"Calcacres\": \"float\",\n",
    "    \"Heat\": \"int\",\n",
    "    \"D Effyr\": \"int\",\n",
    "    \"Extwall\": \"int\",\n",
    "    \"Style\": \"string\",\n",
    "    \"Rmtot\": \"int\",\n",
    "    \"D Grade\": \"string\",\n",
    "    \"Bsmt\": \"int\"\n",
    "}\n",
    "\n",
    "desired_files = filter(lambda file: contains_keyword(file, keywords), fulton_files)\n",
    "\n",
    "# Read desired files and only parse desired cols\n",
    "# Need to ensure LUC is read in as a str so we can filter appropriately\n",
    "desired_files_dfs = [\n",
    "    pd.read_excel(\n",
    "        FULTON_DIR + file,\n",
    "        usecols=digest_cols,\n",
    "        dtype={\"Luc\": \"str\"}\n",
    "    ) for file in desired_files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat selected digest files\n",
    "# Select for LUC = 101 (SFH)\n",
    "# Drop complete duplicates\n",
    "digest_full = pd.concat(desired_files_dfs)\n",
    "digest_full['Luc'] = digest_full['Luc'].astype('str')\n",
    "digest_full = digest_full[digest_full['Luc'] == '101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init len: 3681749\n",
      "Number of dropped complete duplicates: 896087\n",
      "Final len: 2785662\n",
      "Number of dropped nulls from important columns: 19690\n",
      "Number of nulls in column Taxyr: 0\n",
      "Number of nulls in column Parid: 0\n",
      "Number of nulls in column Situs Adrno: 0\n",
      "Number of nulls in column Situs Adrdir: 2763914\n",
      "Number of nulls in column Situs Adrstr: 0\n",
      "Number of nulls in column Situs Adrsuf: 188543\n",
      "Number of nulls in column Cityname: 4745\n",
      "Number of nulls in column Luc: 0\n",
      "Number of nulls in column Calcacres: 0\n",
      "Number of nulls in column Own1: 0\n",
      "Number of nulls in column Own2: 2315696\n",
      "Number of nulls in column Owner Adrno: 63862\n",
      "Number of nulls in column Owner Adradd: 2761024\n",
      "Number of nulls in column Owner Adrdir: 2704437\n",
      "Number of nulls in column Owner Adrstr: 0\n",
      "Number of nulls in column Owner Adrsuf: 209443\n",
      "Number of nulls in column Cityname.1: 12\n",
      "Number of nulls in column Statecode: 256\n",
      "Number of nulls in column Zip1: 841\n",
      "Number of nulls in column Aprtot: 0\n",
      "Number of nulls in column Extwall: 0\n",
      "Number of nulls in column Style: 0\n",
      "Number of nulls in column D Yrblt: 0\n",
      "Number of nulls in column D Effyr: 2244129\n",
      "Number of nulls in column D Yrremod: 2640192\n",
      "Number of nulls in column Rmtot: 0\n",
      "Number of nulls in column Rmbed: 0\n",
      "Number of nulls in column Fixbath: 0\n",
      "Number of nulls in column Bsmt: 0\n",
      "Number of nulls in column Heat: 0\n",
      "Number of nulls in column Sfla: 0\n",
      "Number of nulls in column D Grade: 0\n"
     ]
    }
   ],
   "source": [
    "# After filtering for LUC, we can continue to cast other columns\n",
    "rename = {\n",
    "    \"Taxyr\": \"TAXYR\",\n",
    "    \"Parid\": \"PARID\",\n",
    "    \"Cityname.1\": \"own_cityname\",\n",
    "    \"Zip1\": \"own_zip\",\n",
    "    \"Sfla\": \"sqft_living\",\n",
    "    \"D Yrblt\": \"yr_built\",\n",
    "    \"Rmbed\": \"beds\",\n",
    "    \"Fixbath\": \"baths\",\n",
    "    \"Calcacres\": \"acres\",\n",
    "    \"Heat\": \"heat\",\n",
    "}\n",
    "init_len = len(digest_full)\n",
    "\n",
    "digest_full = digest_full.drop_duplicates()\n",
    "print(f\"Init len: {init_len}\")\n",
    "print(f\"Number of dropped complete duplicates: {init_len - len(digest_full)}\")\n",
    "print(f\"Final len: {len(digest_full)}\")\n",
    "\n",
    "# Drop nulls in important columns\n",
    "drop_nulls_cols = [\n",
    "    \"Taxyr\", \"Parid\", \"Situs Adrno\", \"Situs Adrstr\", \"Luc\", \"D Yrblt\",\n",
    "    \"Sfla\", \"Rmbed\", \"Fixbath\", \"Calcacres\", \"Heat\", \"Extwall\",\n",
    "    \"Style\", \"Rmtot\", \"D Grade\", \"Bsmt\", \"Owner Adrstr\"\n",
    "]\n",
    "\n",
    "init_len = len(digest_full)\n",
    "digest_full = digest_full.dropna(subset=drop_nulls_cols)\n",
    "print(f\"Number of dropped nulls from important columns: {init_len - len(digest_full)}\")\n",
    "\n",
    "# Records nulls and set datatypes\n",
    "for column in digest_full.columns:\n",
    "    digest_full[column] = clean_and_cast_column(digest_full[column], digest_cols)\n",
    "    \n",
    "digest_full = digest_full.rename(columns=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TAXYR\n",
       "2010    207544\n",
       "2011    207578\n",
       "2012    207757\n",
       "2013    208987\n",
       "2014    209878\n",
       "2015    211153\n",
       "2016    201392\n",
       "2017    214320\n",
       "2018    215890\n",
       "2019    217756\n",
       "2020    219842\n",
       "2021    221480\n",
       "2022    222395\n",
       "Name: PARID, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly validate no data quality issues\n",
    "# by looking at number of parcels per year\n",
    "digest_full.groupby(\"TAXYR\")['PARID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It looks like a few parcels are lost between 2015 and 2016 (approx 10K) - this is potentially a flaw in Fulton data, not our own processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a File with all Fulton County Sales for all Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_964\\1001776804.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "keywords = [\"STANDARDS SALES\"]\n",
    "sale_cols = {\n",
    "    \"Taxyr\": \"int\",\n",
    "    \"Parid\": \"string\",\n",
    "    \"Saledt\": \"string\",\n",
    "    \"Luc\": \"string\",\n",
    "    \"SALES PRICE\": \"float\",\n",
    "    \"FAIR MARKET VALUE\": \"float\",\n",
    "    \"DEED TYPE\": \"string\",\n",
    "    \"Saleval\": \"string\",\n",
    "    \"Costval\": \"string\",\n",
    "    \"GRANTOR\": \"string\",\n",
    "    \"GRANTEE\": \"string\",\n",
    "}\n",
    "\n",
    "desired_files = filter(lambda file: contains_keyword(file, keywords), fulton_files)\n",
    "\n",
    "desired_files_dfs = [\n",
    "    pd.read_csv(\n",
    "        FULTON_DIR + file,\n",
    "        sep='\\t',\n",
    "        encoding='latin-1',\n",
    "        usecols=sale_cols,\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        skipfooter=1,\n",
    "        on_bad_lines=\"warn\"\n",
    "    ) for file in desired_files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select for LUC = 101 (SFH)\n",
    "sales_full = pd.concat(desired_files_dfs)\n",
    "sales_full['Luc'] = sales_full['Luc'].astype('str')\n",
    "sales_full = sales_full[sales_full['Luc'] == '101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init len: 275814\n",
      "Number of dropped complete duplicates: 461\n",
      "Final len: 275353\n",
      "Number of nulls in column Taxyr: 0\n",
      "Number of nulls in column Parid: 0\n",
      "Number of nulls in column Luc: 0\n",
      "Number of nulls in column Saledt: 0\n",
      "Number of nulls in column SALES PRICE: 19\n",
      "Number of nulls in column FAIR MARKET VALUE: 0\n",
      "Number of nulls in column DEED TYPE: 2\n",
      "Number of nulls in column Costval: 0\n",
      "Number of nulls in column Saleval: 118\n",
      "Number of nulls in column GRANTOR: 18\n",
      "Number of nulls in column GRANTEE: 8\n"
     ]
    }
   ],
   "source": [
    "# Concat selected sales files\n",
    "# Drop complete duplicates\n",
    "# Record total number of sales\n",
    "rename = {\n",
    "    \"Taxyr\": \"TAXYR\",\n",
    "    \"Parid\": \"PARID\",\n",
    "}\n",
    "\n",
    "init_len = len(sales_full)\n",
    "sales_full = sales_full.drop_duplicates()\n",
    "print(f\"Init len: {init_len}\")\n",
    "print(f\"Number of dropped complete duplicates: {init_len - len(sales_full)}\")\n",
    "print(f\"Final len: {len(sales_full)}\")\n",
    "\n",
    "# Records nulls and set datatypes\n",
    "for column in sales_full.columns:\n",
    "    sales_full[column] = clean_and_cast_column(sales_full[column], sale_cols)\n",
    "    \n",
    "sales_full = sales_full.rename(columns=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TAXYR\n",
       "2011    26777\n",
       "2012    22684\n",
       "2013    26074\n",
       "2014    11711\n",
       "2015    11256\n",
       "2016    14978\n",
       "2017    13210\n",
       "2018    28281\n",
       "2019    29134\n",
       "2020    29570\n",
       "2021    28645\n",
       "2022    33033\n",
       "Name: PARID, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution of data for quick validation\n",
    "sales_full.groupby(\"TAXYR\")['PARID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">SALES PRICE</th>\n",
       "      <th colspan=\"8\" halign=\"left\">FAIR MARKET VALUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAXYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>26777.00</td>\n",
       "      <td>162950.94</td>\n",
       "      <td>630129.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56050.00</td>\n",
       "      <td>189900.00</td>\n",
       "      <td>51718108.00</td>\n",
       "      <td>26777.00</td>\n",
       "      <td>210525.70</td>\n",
       "      <td>292278.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42100.00</td>\n",
       "      <td>115300.00</td>\n",
       "      <td>276200.00</td>\n",
       "      <td>8750000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>22684.00</td>\n",
       "      <td>164550.67</td>\n",
       "      <td>424239.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49500.00</td>\n",
       "      <td>200515.00</td>\n",
       "      <td>20500000.00</td>\n",
       "      <td>22684.00</td>\n",
       "      <td>241854.35</td>\n",
       "      <td>325947.29</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>56600.00</td>\n",
       "      <td>142800.00</td>\n",
       "      <td>314800.00</td>\n",
       "      <td>13698600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>26074.00</td>\n",
       "      <td>166081.78</td>\n",
       "      <td>440832.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47000.00</td>\n",
       "      <td>212000.00</td>\n",
       "      <td>17038094.00</td>\n",
       "      <td>26074.00</td>\n",
       "      <td>238072.86</td>\n",
       "      <td>323868.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39500.00</td>\n",
       "      <td>142225.00</td>\n",
       "      <td>325900.00</td>\n",
       "      <td>6322800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>11711.00</td>\n",
       "      <td>331640.54</td>\n",
       "      <td>351925.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>79000.00</td>\n",
       "      <td>255000.00</td>\n",
       "      <td>455000.00</td>\n",
       "      <td>6350000.00</td>\n",
       "      <td>11711.00</td>\n",
       "      <td>294653.60</td>\n",
       "      <td>320690.06</td>\n",
       "      <td>100.00</td>\n",
       "      <td>63900.00</td>\n",
       "      <td>226960.00</td>\n",
       "      <td>402150.00</td>\n",
       "      <td>6189700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>11256.00</td>\n",
       "      <td>357182.81</td>\n",
       "      <td>392959.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101425.00</td>\n",
       "      <td>275000.00</td>\n",
       "      <td>475000.00</td>\n",
       "      <td>13914719.00</td>\n",
       "      <td>11256.00</td>\n",
       "      <td>314046.58</td>\n",
       "      <td>324030.38</td>\n",
       "      <td>1390.00</td>\n",
       "      <td>74887.50</td>\n",
       "      <td>244970.00</td>\n",
       "      <td>428770.00</td>\n",
       "      <td>6151600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>14978.00</td>\n",
       "      <td>348266.13</td>\n",
       "      <td>401923.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85000.00</td>\n",
       "      <td>258325.00</td>\n",
       "      <td>474500.00</td>\n",
       "      <td>17455046.00</td>\n",
       "      <td>14978.00</td>\n",
       "      <td>346104.72</td>\n",
       "      <td>368631.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91500.00</td>\n",
       "      <td>257500.00</td>\n",
       "      <td>470000.00</td>\n",
       "      <td>6000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>13210.00</td>\n",
       "      <td>386344.64</td>\n",
       "      <td>386724.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>139000.00</td>\n",
       "      <td>294000.00</td>\n",
       "      <td>517500.00</td>\n",
       "      <td>7200000.00</td>\n",
       "      <td>13210.00</td>\n",
       "      <td>306637.00</td>\n",
       "      <td>320307.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75725.00</td>\n",
       "      <td>225900.00</td>\n",
       "      <td>425000.00</td>\n",
       "      <td>6000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>28281.00</td>\n",
       "      <td>268587.37</td>\n",
       "      <td>931256.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>108000.00</td>\n",
       "      <td>360000.00</td>\n",
       "      <td>135635876.00</td>\n",
       "      <td>28281.00</td>\n",
       "      <td>307217.92</td>\n",
       "      <td>359431.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75800.00</td>\n",
       "      <td>198500.00</td>\n",
       "      <td>418000.00</td>\n",
       "      <td>7150000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>29134.00</td>\n",
       "      <td>522038.36</td>\n",
       "      <td>2227323.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>137000.00</td>\n",
       "      <td>379900.00</td>\n",
       "      <td>40120000.00</td>\n",
       "      <td>29134.00</td>\n",
       "      <td>328591.65</td>\n",
       "      <td>367677.75</td>\n",
       "      <td>100.00</td>\n",
       "      <td>107200.00</td>\n",
       "      <td>207000.00</td>\n",
       "      <td>427975.00</td>\n",
       "      <td>7861300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>29570.00</td>\n",
       "      <td>303400.40</td>\n",
       "      <td>1085088.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>379000.00</td>\n",
       "      <td>58800000.00</td>\n",
       "      <td>29570.00</td>\n",
       "      <td>364300.06</td>\n",
       "      <td>393939.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>133500.00</td>\n",
       "      <td>243900.00</td>\n",
       "      <td>467500.00</td>\n",
       "      <td>11350000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>28645.00</td>\n",
       "      <td>363893.16</td>\n",
       "      <td>2274967.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>193000.00</td>\n",
       "      <td>435000.00</td>\n",
       "      <td>126940000.00</td>\n",
       "      <td>28645.00</td>\n",
       "      <td>422773.73</td>\n",
       "      <td>432387.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173100.00</td>\n",
       "      <td>303700.00</td>\n",
       "      <td>529900.00</td>\n",
       "      <td>15000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>33033.00</td>\n",
       "      <td>530580.09</td>\n",
       "      <td>1934406.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>250000.00</td>\n",
       "      <td>537500.00</td>\n",
       "      <td>231058000.00</td>\n",
       "      <td>33033.00</td>\n",
       "      <td>478192.98</td>\n",
       "      <td>476555.17</td>\n",
       "      <td>800.00</td>\n",
       "      <td>205000.00</td>\n",
       "      <td>342600.00</td>\n",
       "      <td>587500.00</td>\n",
       "      <td>9966300.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SALES PRICE                                                          \\\n",
       "            count      mean        std  min       25%       50%       75%   \n",
       "TAXYR                                                                       \n",
       "2011     26777.00 162950.94  630129.89 0.00      0.00  56050.00 189900.00   \n",
       "2012     22684.00 164550.67  424239.44 0.00      0.00  49500.00 200515.00   \n",
       "2013     26074.00 166081.78  440832.36 0.00      0.00  47000.00 212000.00   \n",
       "2014     11711.00 331640.54  351925.01 0.00  79000.00 255000.00 455000.00   \n",
       "2015     11256.00 357182.81  392959.23 0.00 101425.00 275000.00 475000.00   \n",
       "2016     14978.00 348266.13  401923.49 0.00  85000.00 258325.00 474500.00   \n",
       "2017     13210.00 386344.64  386724.40 0.00 139000.00 294000.00 517500.00   \n",
       "2018     28281.00 268587.37  931256.97 0.00      1.00 108000.00 360000.00   \n",
       "2019     29134.00 522038.36 2227323.74 0.00      1.00 137000.00 379900.00   \n",
       "2020     29570.00 303400.40 1085088.76 0.00      1.00 155000.00 379000.00   \n",
       "2021     28645.00 363893.16 2274967.99 0.00      1.00 193000.00 435000.00   \n",
       "2022     33033.00 530580.09 1934406.18 0.00     10.00 250000.00 537500.00   \n",
       "\n",
       "                   FAIR MARKET VALUE                                        \\\n",
       "               max             count      mean       std     min       25%   \n",
       "TAXYR                                                                        \n",
       "2011   51718108.00          26777.00 210525.70 292278.99    0.00  42100.00   \n",
       "2012   20500000.00          22684.00 241854.35 325947.29 1500.00  56600.00   \n",
       "2013   17038094.00          26074.00 238072.86 323868.49    0.00  39500.00   \n",
       "2014    6350000.00          11711.00 294653.60 320690.06  100.00  63900.00   \n",
       "2015   13914719.00          11256.00 314046.58 324030.38 1390.00  74887.50   \n",
       "2016   17455046.00          14978.00 346104.72 368631.02    0.00  91500.00   \n",
       "2017    7200000.00          13210.00 306637.00 320307.43    0.00  75725.00   \n",
       "2018  135635876.00          28281.00 307217.92 359431.09    0.00  75800.00   \n",
       "2019   40120000.00          29134.00 328591.65 367677.75  100.00 107200.00   \n",
       "2020   58800000.00          29570.00 364300.06 393939.77    0.00 133500.00   \n",
       "2021  126940000.00          28645.00 422773.73 432387.60    0.00 173100.00   \n",
       "2022  231058000.00          33033.00 478192.98 476555.17  800.00 205000.00   \n",
       "\n",
       "                                       \n",
       "            50%       75%         max  \n",
       "TAXYR                                  \n",
       "2011  115300.00 276200.00  8750000.00  \n",
       "2012  142800.00 314800.00 13698600.00  \n",
       "2013  142225.00 325900.00  6322800.00  \n",
       "2014  226960.00 402150.00  6189700.00  \n",
       "2015  244970.00 428770.00  6151600.00  \n",
       "2016  257500.00 470000.00  6000000.00  \n",
       "2017  225900.00 425000.00  6000000.00  \n",
       "2018  198500.00 418000.00  7150000.00  \n",
       "2019  207000.00 427975.00  7861300.00  \n",
       "2020  243900.00 467500.00 11350000.00  \n",
       "2021  303700.00 529900.00 15000000.00  \n",
       "2022  342600.00 587500.00  9966300.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another data validation check\n",
    "sales_full.groupby(\"TAXYR\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocode Digest and Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Validate CRS: True\n"
     ]
    }
   ],
   "source": [
    "# Read in parcel boundary data from Fulton County 2022 record\n",
    "geo_parcels = gpd.read_file(\"./data/fulton_parcels.geojson\")\n",
    "geo_parcels = geo_parcels[[\"ParcelID\", \"OBJECTID\", \"geometry\"]]\n",
    "geo_parcels = geo_parcels.rename(columns={\"ParcelID\": \"PARID\"})\n",
    "# Ensure no duplicates for merging\n",
    "print(len(geo_parcels[geo_parcels.duplicated(subset=[\"PARID\"])]))\n",
    "\n",
    "# Read in neighborhood boundaries and stats from Neighborhood Nexus\n",
    "geo_atl_nsa = gpd.read_file(\"./data/atl_nsa.geojson\")\n",
    "geo_atl_nsa = geo_atl_nsa.rename(columns={\"NEIGHBORHO\": \"neighborhood\", \"geometry\": \"nsa_boundary\"})\n",
    "geo_atl_nsa = geo_atl_nsa[[\"neighborhood\", \"nsa_boundary\"]]\n",
    "# Ensure no duplicates for merging\n",
    "print(len(geo_atl_nsa[geo_atl_nsa.duplicated(subset=[\"neighborhood\"])]))\n",
    "\n",
    "# Validate identical CRS for spatial join\n",
    "geo_parcels = geo_parcels.set_geometry(\"geometry\")\n",
    "geo_atl_nsa = geo_atl_nsa.set_geometry(\"nsa_boundary\")\n",
    "print(f\"Validate CRS: {geo_parcels.crs == geo_atl_nsa.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick\\Documents\\code\\equity-extraction\\equity-extraction\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3493: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "# Get city name for each parcel with a spatial join\n",
    "geo_parcels = gpd.sjoin(geo_parcels, geo_atl_nsa, how=\"left\", op=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of records not geo matched in digest: 6556\n",
      "Num of records not geo matched in sales: 852\n"
     ]
    }
   ],
   "source": [
    "# Merge parcel boundaries and cities with digest and salses data\n",
    "# Just do this for record keeping purposes (e.g. how many can't be matched)\n",
    "# Actual merging will be done in analysis file due to data format issues\n",
    "digest_geo = digest_full.merge(geo_parcels, on=\"PARID\", how=\"inner\")\n",
    "sales_geo = sales_full.merge(geo_parcels, on=\"PARID\", how=\"inner\")\n",
    "\n",
    "print(f\"Num of records not geo matched in digest: {len(digest_full) - len(digest_geo)}\")\n",
    "print(f\"Num of records not geo matched in sales: {len(sales_full) - len(sales_geo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parcels in ATL: 1002694\n",
      "Number of sales in ATL: 110896\n"
     ]
    }
   ],
   "source": [
    "# Parcels and sales in ATL\n",
    "digest_atl = digest_geo[digest_geo['neighborhood'].notna()]\n",
    "sales_atl = sales_geo[sales_geo['neighborhood'].notna()]\n",
    "print(f\"Number of parcels in ATL: {len(digest_atl)}\")\n",
    "print(f\"Number of sales in ATL: {len(sales_atl)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parcel geometry data\n",
    "OUTPUT_PATH = 'output/parcels_geo'\n",
    "geo_parcels.to_csv(OUTPUT_PATH + '.csv', index=False)\n",
    "\n",
    "# Save parcel data without geometry data so Parquet format works\n",
    "OUTPUT_PATH = 'output/'\n",
    "digest_full.to_parquet(OUTPUT_PATH + 'digest_full.parquet', index=False)\n",
    "sales_full.to_parquet(OUTPUT_PATH + 'sales_full.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equity-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
